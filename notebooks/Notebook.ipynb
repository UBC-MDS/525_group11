{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 525 Team 11 Milestone 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os,sys,inspect\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "import dask.dataframe as dd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\miniconda3\\envs\\525\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the folders\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir) # this refers to the project root folder\n",
    "raw_folder = parentdir + \"/data/raw/\"\n",
    "\n",
    "processed_folder = parentdir + \"/data/processed/\"\n",
    "if not os.path.exists(raw_folder):\n",
    "    os.makedirs(raw_folder)\n",
    "    \n",
    "if not os.path.exists(processed_folder):\n",
    "    os.makedirs(processed_folder)\n",
    "\n",
    "combined_file = processed_folder + \"combined_data.csv\"\n",
    "\n",
    "files_to_dl = [\"data.zip\"] # need only this zip file\n",
    "\n",
    "# avoid re-loading the data if the file already exists locally\n",
    "force_download = False # set to True to re-download and unzip the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M1 - 3. Download the data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        if (force_download or not os.path.exists(raw_folder + file[\"name\"])):\n",
    "            os.makedirs(raw_folder, exist_ok=True) # create the folder if not exists\n",
    "            urlretrieve(file[\"download_url\"], raw_folder + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extract the zip file\n",
    "n_files = len(os.listdir(raw_folder))\n",
    "if (force_download or n_files != 31): # if we must unzip the latest downloaded file or the file was not unzipped\n",
    "    with zipfile.ZipFile(os.path.join(raw_folder, \"data.zip\"), 'r') as f:\n",
    "        f.extractall(raw_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M1 - 4. Combine the data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Combine the data using `Pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 149.07 MiB, increment: 0.00 MiB\n",
      "Wall time: 9min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "import pandas as pd\n",
    "use_cols = [\"time\", \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\"]\n",
    "files = glob.glob(raw_folder + '*NSW.csv') # exclude observed_daily_rainfall_SYD\n",
    "\n",
    "df = pd.concat((pd.read_csv(file, index_col=0, usecols=use_cols)\n",
    "                .assign(model=file[max(file.rfind('/'), file.rfind('\\\\'))+1:file.index(\"_daily\")])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(combined_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the combined file: 5.618728716857731 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the combined file:\", os.path.getsize(combined_file)/(2**30), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(combined_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1  1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "2  1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "3  1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "4  1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "        model  \n",
       "0  ACCESS-CM2  \n",
       "1  ACCESS-CM2  \n",
       "2  ACCESS-CM2  \n",
       "3  ACCESS-CM2  \n",
       "4  ACCESS-CM2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Combine the data using `Dask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %%memit\n",
    "# dask_combined_file = processed_folder + \"dask_combined_data.csv\"\n",
    "# ddf = dd.read_csv(raw_folder + '*NSW.csv', assume_missing=True, usecols=use_cols, include_path_column=True)\n",
    "# ddf.to_csv(dask_combined_file, single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Size of the combined file:\", os.path.getsize(dask_combined_file)/(2**30), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.63 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1  1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "2  1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "3  1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "4  1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "        model  \n",
       "0  ACCESS-CM2  \n",
       "1  ACCESS-CM2  \n",
       "2  ACCESS-CM2  \n",
       "3  ACCESS-CM2  \n",
       "4  ACCESS-CM2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ddf = dd.read_csv(combined_file)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team have **downloaded the data** and **executed the data combination script using `Pandas` on 4 laptops**. Below are the detailed results:\n",
    "\n",
    "OS|CPU|Memory|Runtime|Memory\n",
    "--|---|------|-------|------\n",
    "macOS BigSur|2.7 GHz Dual-Core Intel Core i5|16 GB|CPU times: user 7min 37s, sys: 24.5 s, total: 8min 1s. Wall time: 8min 35s|peak memory: 155.76 MiB, increment: 0.04 MiB\n",
    "Windows 10 Education Insider Preview|Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz 2.30 GHz|16 GB|Wall time: 8min 55s|peak memory: 138.60 MiB, increment: 0.25 MiB\n",
    "macOS Catalina version 10.15.7|2.4 GHz Quad-Core Intel Core i5|8 GB|CPU times: user 5min 45s, sys: 21.5 s, total: 6min 7s. Wall time: 6min 15s|peak memory: 125.83 MiB, increment: 0.25 MiB\n",
    "Windows 10 Education|Intel(R) Core(TM) i7-8550U CPU @ 1.80 GHz 1.99 GHz| 16 GB|Wall time: 10min 11s|peak memory: 140.70 MiB, increment: 0.20 MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result table above, the **runtime varied across machines** depending on their configurations, but they **all took considerable amount of time and memory**. It is noteworthy that:\n",
    "\n",
    "* Due to the limited hard drive space, we had to comment out the script used for **combining data** files with `Dask`; also in the previous execution, using `Dask` to **combine these files actually took more time** than using `Pandas`. \n",
    "\n",
    "* `Dask`'s `read_csv` function is, however, super **fast** in comparison to using `Pandas`'s due to the fact that `Pandas` **loads the whole data object into memory** whilst `Dask` **loads data in chunks** and applies parallel processing.\n",
    "\n",
    "**In conclusion, merging csv files into one giant file and loading it every time is clearly not an efficient way to work with big data files.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M1 - 5. Load the combined CSV to memory and perform a simple EDA in `Python`\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Changing `dtype` of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1  1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "2  1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "3  1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "4  1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "        model  \n",
       "0  ACCESS-CM2  \n",
       "1  ACCESS-CM2  \n",
       "2  ACCESS-CM2  \n",
       "3  ACCESS-CM2  \n",
       "4  ACCESS-CM2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the combined dataframe to the memory\n",
    "df = pd.read_csv(\"../data/processed/combined_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time              object\n",
       "lat_min          float64\n",
       "lat_max          float64\n",
       "lon_min          float64\n",
       "lon_max          float64\n",
       "rain (mm/day)    float64\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data types of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>within float32 range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lat_min</th>\n",
       "      <td>-3.646739e+01</td>\n",
       "      <td>-29.900000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat_max</th>\n",
       "      <td>-3.600000e+01</td>\n",
       "      <td>-27.906064</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon_min</th>\n",
       "      <td>1.406250e+02</td>\n",
       "      <td>153.750000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon_max</th>\n",
       "      <td>1.412500e+02</td>\n",
       "      <td>155.625000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <td>-3.807373e-12</td>\n",
       "      <td>432.939515</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        min         max within float32 range\n",
       "lat_min       -3.646739e+01  -29.900000                 True\n",
       "lat_max       -3.600000e+01  -27.906064                 True\n",
       "lon_min        1.406250e+02  153.750000                 True\n",
       "lon_max        1.412500e+02  155.625000                 True\n",
       "rain (mm/day) -3.807373e-12  432.939515                 True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if the max and min values of the float64-type columns are within the range of `float32`\n",
    "df_numeric_summary = df.describe().loc[[\"min\", \"max\"], :].T\n",
    "df_numeric_summary[\"within float32 range\"] = df_numeric_summary[[\"min\", \"max\"]].apply(lambda x:\n",
    "                                                                                      \"True\" if (x[\"min\"] > np.finfo(np.float32).min\n",
    "                                                                                                 and x[\"max\"] < np.finfo(np.float32).max)\n",
    "                                                                                             else \"False\", axis=1)\n",
    "df_numeric_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64 (default): 2498.71 MB\n",
      "Memory usage with float32: 1249.36 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64 (default): {df[['lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with object (default) for the time column: 499.74 MB\n",
      "Memory usage with datetime64 for the time column: 499.74 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with object (default) for the time column: {df[['time']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with datetime64 for the time column: {df[['time']].astype('datetime64[ns]', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MPI-ESM-1-2-HAM', 'AWI-ESM-1-1-LR', 'NorESM2-LM', 'ACCESS-CM2',\n",
       "       'FGOALS-f3-L', 'CMCC-CM2-HR4', 'MRI-ESM2-0', 'GFDL-CM4',\n",
       "       'BCC-CSM2-MR', 'EC-Earth3-Veg-LR', 'CMCC-ESM2', 'NESM3',\n",
       "       'MPI-ESM1-2-LR', 'ACCESS-ESM1-5', 'FGOALS-g3', 'INM-CM4-8',\n",
       "       'MPI-ESM1-2-HR', 'TaiESM1', 'NorESM2-MM', 'CMCC-CM2-SR5',\n",
       "       'KIOST-ESM', 'INM-CM5-0', 'MIROC6', 'BCC-ESM1', 'GFDL-ESM4',\n",
       "       'CanESM5', 'SAM0-UNICON'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the `model` column's unique values\n",
    "df.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with object (default) for the model column: 499.74 MB\n",
      "Memory usage with string for the model column: 499.74 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with object (default) for the model column: {df[['model']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with string for the model column: {df[['model']].astype('string', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>memory savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lat_min</td>\n",
       "      <td>249.871372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lat_max</td>\n",
       "      <td>249.871372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lon_min</td>\n",
       "      <td>249.871372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lon_max</td>\n",
       "      <td>249.871372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rain (mm/day)</td>\n",
       "      <td>249.871372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column name  memory savings\n",
       "0           time        0.000000\n",
       "1        lat_min      249.871372\n",
       "2        lat_max      249.871372\n",
       "3        lon_min      249.871372\n",
       "4        lon_max      249.871372\n",
       "5  rain (mm/day)      249.871372\n",
       "6          model        0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating memory savings for each column\n",
    "df_memory_savings = pd.DataFrame(columns = df.columns).T.reset_index().rename(columns={'index': 'column name'})\n",
    "\n",
    "list_savings = []\n",
    "savings = 0\n",
    "for col in df.columns:\n",
    "    if df[col].dtypes == \"float64\":\n",
    "        savings = (df[[col]].memory_usage().sum() / 1e6) - (df[[col]].astype('float32', errors='ignore').memory_usage().sum() / 1e6)\n",
    "        list_savings.append(savings)\n",
    "        savings = 0\n",
    "    elif col == \"time\":\n",
    "        savings = (df[[\"time\"]].memory_usage().sum() / 1e6) - (df[[col]].astype('datetime64[ns]', errors='ignore').memory_usage().sum() / 1e6)\n",
    "        list_savings.append(savings)\n",
    "        savings = 0\n",
    "    else:\n",
    "        savings = (df[[\"model\"]].memory_usage().sum() / 1e6) - (df[[col]].astype('string', errors='ignore').memory_usage().sum() / 1e6)\n",
    "        list_savings.append(savings)\n",
    "        savings = 0\n",
    "\n",
    "df_memory_savings['memory savings'] = pd.Series(list_savings).values\n",
    "df_memory_savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMemory savings due to changing the data types of the columns: 1249.36 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\" + f\"Memory savings due to changing the data types of the columns: {df_memory_savings['memory savings'].sum():.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Loading just the columns we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with all columns: 3498.20 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with all columns: {df[['time', 'lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)', 'model']].memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of the reduced dataframe: 2498.71 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_max   lon_max  rain (mm/day)            model\n",
       "0  1889-01-01 12:00:00 -33.574619  143.4375   4.244226e-13  MPI-ESM-1-2-HAM\n",
       "1  1889-01-02 12:00:00 -33.574619  143.4375   4.217326e-13  MPI-ESM-1-2-HAM\n",
       "2  1889-01-03 12:00:00 -33.574619  143.4375   4.498125e-13  MPI-ESM-1-2-HAM\n",
       "3  1889-01-04 12:00:00 -33.574619  143.4375   4.251282e-13  MPI-ESM-1-2-HAM\n",
       "4  1889-01-05 12:00:00 -33.574619  143.4375   4.270161e-13  MPI-ESM-1-2-HAM"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping `lat_min` and `lon_min` columns\n",
    "df_reduced = df.drop(['lat_min', 'lon_min'], axis=1);\n",
    "print(f\"Memory usage of the reduced dataframe: {df_reduced.memory_usage().sum() / 1e6:.2f} MB\")\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMemory savings due to loading not all columns: 999.49 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\" + f\"Memory savings due to loading not all columns: {df[['lat_min', 'lon_min']].memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Loading data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 7295.00 MiB, increment: 5542.13 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "df = pd.read_csv(\"../data/processed/combined_data.csv\")\n",
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with loading all data of the 'model' column and perform value_counts EDA: 7649.36 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with loading all data of the 'model' column and perform value_counts EDA: {7295 * 1.048576:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840.0\n",
      "ACCESS-ESM1-5       1610700.0\n",
      "AWI-ESM-1-1-LR       966420.0\n",
      "BCC-CSM2-MR         3035340.0\n",
      "BCC-ESM1             551880.0\n",
      "CMCC-CM2-HR4        3541230.0\n",
      "CMCC-CM2-SR5        3541230.0\n",
      "CMCC-ESM2           3541230.0\n",
      "CanESM5              551880.0\n",
      "EC-Earth3-Veg-LR    3037320.0\n",
      "FGOALS-f3-L         3219300.0\n",
      "FGOALS-g3           1287720.0\n",
      "GFDL-CM4            3219300.0\n",
      "GFDL-ESM4           3219300.0\n",
      "INM-CM4-8           1609650.0\n",
      "INM-CM5-0           1609650.0\n",
      "KIOST-ESM           1287720.0\n",
      "MIROC6              2070900.0\n",
      "MPI-ESM-1-2-HAM      966420.0\n",
      "MPI-ESM1-2-HR       5154240.0\n",
      "MPI-ESM1-2-LR        966420.0\n",
      "MRI-ESM2-0          3037320.0\n",
      "NESM3                966420.0\n",
      "NorESM2-LM           919800.0\n",
      "NorESM2-MM          3541230.0\n",
      "SAM0-UNICON         3541153.0\n",
      "TaiESM1             3541230.0\n",
      "dtype: object\n",
      "peak memory: 3699.65 MiB, increment: 2144.54 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "values = pd.Series(dtype=object)\n",
    "for chunk in pd.read_csv(\"../data/processed/combined_data.csv\", chunksize=10_000_000):\n",
    "    values = values.add(chunk['model'].value_counts(), fill_value=0)\n",
    "print(values.astype(object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with loading in chunks of the 'model' column and perform value_counts EDA: 3879.36 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with loading in chunks of the 'model' column and perform value_counts EDA: {3699.65 * 1.048576:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMemory savings due to loading in chunks: 3770.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\" + f\"Memory savings due to loading in chunks: {(7295-3699.65) * 1.048576:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 `Python` Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team decided to try 3 approaches to reduce memory usage when performing the EDA in `Python`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Approach 1. Change the data types of the columns in the dataframe.**\n",
    "\n",
    "There are 2 columns of the `object` type (`time` and `model`) and 5 columns of the `float64` type (`lat_min`, `lat_max`, `lon_min`, `lon_max`, and `rain (mm/day)`).\n",
    "\n",
    "* The summary table for the numeric columns shows that they are within the range of the `float32` data type, i.e. the numeric columns' highest values do not exceed the `float32` maximum number, and their lowest values are not less than the `float32` minimum. \n",
    "\n",
    "* Changing the data type for these columns into the `float32` type **leads to the two-fold decrease in memory usage**, with the **reduction from 2498.71 MB to 1249.36 MB**. \n",
    "\n",
    "* It is related to the fact that `float64` allocates twice as much memory as `float32`, since `float64` can store much larger numbers than `float32`.\n",
    "\n",
    "Regarding the `time` and `model` columns, 499.74 MB of memory was allocated for each of the columns. Interestingly, changing the data type for the `time` and `model` columns to `datetime64[ns]` and `string` respectively did not change the amount of memory used.\n",
    "\n",
    "Based on the above, we can **conclude that the `datetime64`, `string`, and `object` data types allocate the same amount of memory for storing data**. For this reason, **in order to reduce memory usage it is reasonable to change the data type for numeric columns**.\n",
    "\n",
    "> In this particular case, **memory savings** due to changing the data types of the numeric columns are **1249.36 MB**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Approach 2. Load the specific columns we are interested in.**\n",
    "\n",
    "For the sake of the task, we suppose that now we are not interested in the `lat_min` and `lon_min` columns, i.e. these columns do not play a big role in our prediction problem. \n",
    "\n",
    "* **Dropping the specified columns reduced the memory usage** from **3498.20 MB** to **2498.71 MB**.\n",
    "\n",
    "This shows the efficiency of loading only those columns that are necessary for a specific task in terms of memory usage when working with big data.\n",
    "\n",
    "> Here, **memory savings** due to loading not all columns (by dropping two columns) are **999.49 MB**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Approach 3. Load in data in chunks.**\n",
    "\n",
    "For the sake of this task, we assume that now we are only interested in the `model` column and we performed `value_counts` EDA on the `model` column. \n",
    "\n",
    "* **Loading data** from the `model` column **in chunks reduced the memory usage** from **7649.36 MB** to **3879.36 MB**.\n",
    "\n",
    "* This shows the efficiency of loading data in chunk in terms of memory usage when working with big data.\n",
    "\n",
    "> Here, **memory savings** due to loading data in chunks are **3770.00 MB**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M1 - 6. Perform a simple EDA in `R`\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_folder = os.path.join(parentdir,\"data\", \"processed\")\n",
    "\n",
    "input_path = os.path.join(processed_folder, \"combined_data.csv\")\n",
    "output_path = os.path.join(processed_folder, \"combined_data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %memit\n",
    "\n",
    "# df = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %memit\n",
    "\n",
    "# feather.write_feather(df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "\n",
    "# install.packages(\"dplyr\")\n",
    "# library(arrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Use `Feather` to transfer from `Python` to `R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'arrow'\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:utils':\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[38;5;246m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[38;5;246m<int>\u001b[39m\u001b[23m\n",
      "\u001b[38;5;250m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[38;5;250m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[38;5;250m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[38;5;250m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[38;5;250m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[38;5;250m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[38;5;250m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[38;5;250m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[38;5;250m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[38;5;250m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[38;5;246m# ... with 17 more rows\u001b[39m\n",
      "Time difference of 37.20232 secs\n",
      "Wall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(dplyr)\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"../data/processed/combined_data.feather\")\n",
    "print(class(r_table))\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time() \n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 `R` Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a thorough discussion, our team have reached a **consensus that `Feather` file is the most suitable approach to transfer the dataframe from `Python` to `R`**. \n",
    "\n",
    "> We used the **speed** of read / write and the **ability to support various operations** as the **criteria** to make the decision.\n",
    "\n",
    "* As the input data is around 5.7 GB, it is extremely slow to use `Pandas` exchange, hence its rejection. \n",
    "\n",
    "* We do not select `Arrow` exchange as it only supports some operations ([link in Gittu's lecture note](https://arrow.apache.org/docs/r/articles/dataset.html)). \n",
    "\n",
    "* `Parquet` file, even though is quite fast, is still slower than `Feather` V2 version when being read. \n",
    "\n",
    "* Similarly, it is much faster to write into a `Feather` file than a `Parquet` file from a `Python` dataframe ([link in Gittu's lecture note](https://ursalabs.org/blog/2020-feather-v2/)). \n",
    "\n",
    "* Even though a `Parquet` file can save more storage space, it is not a main concern for us as storage cost is cheap given this file size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
