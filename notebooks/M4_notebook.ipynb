{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Milestone 4:*** In this milestone, you will deploy the machine learning model you trained in milestone 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone 4 checklist :\n",
    "\n",
    "- [x] Use an EC2 instance. \n",
    "> Please note that our group created a new EC2 instance (Owner: student84) for `task 2` deployment of our API. \n",
    "- [x] Develop your API here in this notebook.\n",
    "- [x] Copy it to ```app.py``` file in EC2 instance.\n",
    "- [x] Run your API for other consumers and test among your colleagues.\n",
    "- [x] Summarize your journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Develop your API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Script: https://github.com/UBC-MDS/525_group11/blob/main/scripts/app.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 1. Load your model here\n",
    "model = joblib.load(\"model.joblib\")\n",
    "\n",
    "# 2. Define a prediction function\n",
    "def return_prediction(data):\n",
    "\n",
    "    # format input_data here so that you can pass it to model.predict()\n",
    "\n",
    "    return model.predict(np.array([data]))\n",
    "\n",
    "# 3. Set up home page using basic html\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    # feel free to customize this if you like\n",
    "    return \"\"\"\n",
    "    <h1>Welcome to our rain prediction service</h1>\n",
    "    To use this service, make a JSON post request to the /predict url with 5 climate model outputs.\n",
    "    \"\"\"\n",
    "\n",
    "# 4. define a new route which will accept POST requests and return model predictions\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def rainfall_prediction():\n",
    "    content = request.json  # this extracts the JSON content we sent\n",
    "    inputs = content[\"data\"]\n",
    "    prediction = return_prediction(inputs)\n",
    "    results = {\"Input\": inputs, \"Prediction\": prediction.tolist()}  # return whatever data you wish, it can be just the prediction\n",
    "                     # or it can be the prediction plus the input data, it's up to you\n",
    "    return jsonify(results)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy your API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Screenshot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/m4_task_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please note that our group created a new EC2 instance (Owner: student84) for task 2 deployment of our API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarize your journey from Milestone 1 to Milestone 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Throughout these 4 milestones, our group sequentially took on the roles of 1. Data Engineers, 2. Infrastructure Engineers, 3. Data Scientists, and 4. DevOps to perform prediction tasks on the large `daily rainfall in Australia` [dataset](https://figshare.com/articles/dataset/Daily_rainfall_over_NSW_Australia/14096681) (5.7 GB), and we have achieved the following 4 objectives in each of the milestones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`Milestone 1`: We got the data from the web using API; we processed it locally, and converted it to an efficient file format. Specifically,**\n",
    "\n",
    "    * We acknowledged that it was both memory-wide costly and speed-wide costly to load big data (csv files) using `Pandas`.   \n",
    "    * As a result, we tried 3 different approaches to reduce memory usage when performing EDA in Python, including:\n",
    "        1. changing the columns' data types in the dataframe; \n",
    "        2. loading only the columns we are interested in; \n",
    "        3. loading data in chunks.\n",
    "    * Additionally, we found that `Feather` file format is the most speedy and flexible approach to transfer dataframe from Python to R in our case.\n",
    "    \n",
    "    \n",
    "* **`Milestone 2`: We moved the data to the cloud via AWS; we setup infrastructure in cloud, and made data ready for Machine Learning task. Specifically,**\n",
    "\n",
    "    * We setup our own `EC2` instance, `S3` bucket, and `TLJH` (Tiny Little JupyterHub).\n",
    "    * We moved the `daily rainfall in Australia` csv file from `Milestone 1` data folder to our `S3` bucket in cloud.\n",
    "    * We then got the data from `S3` into our `TLJH` and wrangled the data into a format suitable for training a machine learning model later.\n",
    "    * Finally we sent back the ready-to-use data to `S3` in cloud.\n",
    "\n",
    "\n",
    "* **`Milestone 3`: We setup the distributed infrastructure `EMR-Spark` cluster in cloud, and developed a Machine Learning model in `Spark` using the ready-to-use data stored in S3 from `Milestone 2`. Specifically,**\n",
    "\n",
    "    * We setup our `EMR` cluster with `Spark` and `TLJH`.\n",
    "    * We setup Firefox as web browser for `EMR` and configured FoxyProxy for Firefox.\n",
    "    * On `TLJH` running the `Spark` engine, we developed a Machine Learning model using `scikit-learn` and obtained the best hyperparameter settings using `Spark`'s `MLlib`.\n",
    "\n",
    "\n",
    "* **`Milestone 4`: We deployed the Machine Learning model we trained from `Milestone 3` in cloud using `Flask` so that other consumers can use it. Specifically,**\n",
    "\n",
    "    * We developed our API called `app.py` using `Flask` on `TLJH`, where we created a new endpoint that accepts a POST request of the 25 features from our user and returns a prediction to the user based on the trained Machine Learning model.\n",
    "    * We deployed our API successfully and made our server available at our `EC2` instance's IP address on port 8080. \n",
    "    * Furthermore, we made our server persistent using `screen`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From taking this course and working on these 4 milestones, our team has now gained a better understanding of how to work with a large dataset, storing and accessing them in cloud, while building and deploying machine learning models in cloud.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
